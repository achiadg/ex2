# R markdown for naive-bayes algorhitm
## setup
```{r setup}
knitr::opts_knit$set(root.dir = 'C:/Users/אחיעד/Desktop/data science/ass2/prediction2')
getwd()
```

## read train.csv into dataframe
```{r}
df <- read.csv("C:/Users/אחיעד/Desktop/data science/ass2/Titanic/train.csv",na.strings = "")
```

## using str to identify data types
```{r}
str(df)
```

## convert Survived column and Pclass column to factors
```{r}
df$Survived<- as.factor(df$Survived)
df$Pclass<- as.factor(df$Pclass)
```

## data summary
```{r}
summary(df)
```
## remove features from df
```{r}
df <- df[,-c(1,4,9)]
```

## devide into factors and numerics columns
```{r}
cols<- 1:dim(df)[2]
factors <- cols[sapply(df,is.factor)]
numerics <- cols[!sapply(df,is.factor)]
```

## We now tide the data two times: the first is for categorial data and the second for numeric data.
```{r}
#install.packages("tidyr")
library(tidyr)
df_tidy_factors<-gather(df[,factors],"feature","value", -1)
df_tidy_numerics<-gather(cbind(Survived=df[,1],df[,numerics]),"feature","value",-1)

```


## plot for factor columns
```{r}
#install.packages("ggplot2")
library(ggplot2)
qplot(x=value,data=df_tidy_factors,fill=Survived) + facet_grid(~feature,scales="free")
```


## plot for numerical columns
```{r}
qplot(x=value,data=df_tidy_numerics,fill=Survived) + facet_grid(~feature,scales="free")
```
### Model Creation
Split the data into train and test sets

```{r}
rows<- nrow(df)
indices <- sample(1:rows,rows*0.8)
train<- df[indices,]
test<- df[-indices,]
```

## we trained the model:naive bayes, without using the caret library, on the train data set.
```{r}
#install.packages('e1071')
#load e1071 library and invoke naiveBayes method
library(e1071)
nb_model <- naiveBayes(Survived~.,data = train)
nb_model
```


## we predict the naive bayes model on the test data set, in the prediction process we pass the na fields in the data set, because the prediction does not succedd with na fields.
this prediction is in order to train our model, and to get better results.
```{r}
nb_test_predict <- predict(nb_model,test[,-1] ,na.action = na.pass)

```

## we Use a confusion matrix to evaluate the prediction results
```{r}
table(pred=nb_test_predict,true=test$Survived)

```


## Calculate the model's test accuracy.
```{r}
mean(nb_test_predict==test$Survived)
```

## load the test file, with na as ""
```{r}
new_df <-read.csv('C:/Users/אחיעד/Desktop/data science/ass2/Titanic/test.csv',na.strings = "")
```

## Create a vector with the PassengerIds of records in the test file. 
```{r}
ids<- new_df$PassengerId
```

## remove features from new_df(the test file)
```{r}
new_df$Pclass<- as.factor(new_df$Pclass)
new_df<- new_df[,-c(1,3,8)]
```


## Another thing that is going to make troubles is that the test data contains some new levels in the *Cabin* feature that did not appear in the train data (you can check it by applying *Summary* on the test data). Add these new levels to the model.

### Getting the levels of the "Cabin" feature from a model *m*: m$xlevels[["Cabin"]]

### Getting the levels of the "Cabin" feature from a dataframe *d*: levels(d$Cabin)

### Union operation: union(x,y)

```{r}
nb_model$xlevels[["Cabin"]] <- union(nb_model$xlevels[["Cabin"]], levels(new_df$Cabin))
```


## we predict the naive bayes model on the new_df data set, in the prediction process we pass the na fields in the data set, because the prediction does not succedd with na fields.  this prediction is in order to predict the test.csv file. 
```{r}
new_pred_nb_model<- predict(nb_model,new_df,na.action = na.pass)
```

### Write the *PassengerId* and *Survived* attributes to a csv file.
```{r}
res <- cbind(PassengerId=ids,Survived=as.character(new_pred_nb_model))
write.csv(res,file="C:/Users/אחיעד/Desktop/data science/ass2/prediction2/output.csv",row.names = F)
```